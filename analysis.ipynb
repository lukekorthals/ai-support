{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from scripts.utils import create_file_list, deduplicate_highest_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEEK_NUMBER = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading global settings\n",
    "with open(\"settings.yaml\") as f:\n",
    "    settings = yaml.safe_load(f)\n",
    "\n",
    "# Global settings\n",
    "WEEK = settings[\"weeks\"][WEEK_NUMBER]\n",
    "STUDENT_SUBMISSION_TEMPLATE = settings[\"global\"][\"paths\"][\"student_submission_template\"]\n",
    "STUDENT_SUBMISSION_JSON_TEMPLATE = settings[\"global\"][\"paths\"][\"student_submission_json_template\"]\n",
    "SUBMISSION_PATH = settings[\"global\"][\"paths\"][\"submissions\"]\n",
    "\n",
    "# Global canvas settings\n",
    "COURSE_ID = settings[\"global\"][\"canvas\"][\"course_id\"]\n",
    "ASSIGNMENT_ID = WEEK[\"canvas\"][\"assignment_id\"]\n",
    "QUIZ_ID = WEEK[\"canvas\"][\"quiz_id\"]\n",
    "R_QUIZ_QUESTION_ID = WEEK[\"canvas\"][\"r_quiz_question_id\"]\n",
    "ADV_QUIZ_QUESTION_ID = WEEK[\"canvas\"][\"adv_quiz_question_id\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_reports = deduplicate_highest_attempt(create_file_list(\"submissions\", [\"LLMCompletionReport.md\", f\"ass-{ASSIGNMENT_ID}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = {\n",
    "    \"student\": [],\n",
    "    \"question\": [],\n",
    "    \"llm_points\": [],\n",
    "    \"llm_explanation\": []\n",
    "}\n",
    "for completion_report in completion_reports:\n",
    "    with open(completion_report) as f:\n",
    "        text = f.read()\n",
    "\n",
    "    indicators = re.compile(r\"Question (#\\w+)\").findall(text)\n",
    "    student = [re.compile(r\"(stu-\\d+)\").search(completion_report).group()] * len(indicators)\n",
    "    \n",
    "    points = []\n",
    "    explanations = []\n",
    "    for indicator in indicators:\n",
    "        current_text = text[text.find(indicator):len(text)]\n",
    "        current_text = current_text[current_text.find(\"grading\"):len(current_text)]\n",
    "        current_text = current_text[current_text.find(\"Completion Choices\"):len(current_text)]\n",
    "        explanation_text = current_text[current_text.find(\"<explanation>\")+len(\"<explanation>\"):current_text.find(\"</explanation>\")]\n",
    "        explanations.append(explanation_text)\n",
    "        current_text = current_text[current_text.find(\"<points>\")+len(\"<points>\"):current_text.find(\"</points>\")]\n",
    "        points.append(float(current_text))\n",
    "    \n",
    "    dat[\"student\"] += student\n",
    "    dat[\"question\"] += indicators\n",
    "    dat[\"llm_points\"] += points\n",
    "    dat[\"llm_explanation\"] += explanations\n",
    "    \n",
    "\n",
    "dat = pd.DataFrame(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.to_csv(f\"grading/week-{WEEK_NUMBER}_llm_grades.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pips-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
